# Logstash Configuration v8.0+
# Purpose: Log processing configuration for enrollment system with enhanced security and audit capabilities

# Global settings
pipeline.workers: ${PIPELINE_WORKERS}
pipeline.batch.size: 125
pipeline.batch.delay: 50
queue.type: persisted
queue.max_bytes: ${QUEUE_MAX_BYTES}

# Input plugins configuration
input {
  # Filebeat/Beats input with enhanced security
  beats {
    port => "${BEATS_PORT}"
    ssl => true
    ssl_certificate => "/etc/logstash/certs/logstash.crt"
    ssl_key => "/etc/logstash/certs/logstash.key"
    ssl_verify_mode => "force_peer"
    ssl_cipher_suites => [
      "TLS_AES_256_GCM_SHA384",
      "TLS_CHACHA20_POLY1305_SHA256"
    ]
    client_inactivity_timeout => 60
    include_codec_tag => true
  }

  # HTTP input for direct log ingestion
  http {
    port => "${HTTP_PORT}"
    ssl => true
    ssl_certificate => "/etc/logstash/certs/logstash.crt"
    ssl_key => "/etc/logstash/certs/logstash.key"
    ssl_verify_mode => "force_peer"
    codec => json
    additional_codecs => {
      "application/x-ndjson" => json_lines
    }
    response_headers => {
      "Content-Type" => "application/json"
      "X-Content-Type-Options" => "nosniff"
      "X-Frame-Options" => "DENY"
    }
  }
}

# Filter plugins configuration
filter {
  # Add processing timestamp and metadata
  mutate {
    add_field => {
      "environment" => "${ENV:production}"
      "application" => "enrollment-system"
      "log_source" => "%{[agent][hostname]}"
      "processing_timestamp" => "%{@timestamp}"
    }
  }

  # Parse application logs
  if [type] == "application" {
    grok {
      match => {
        "message" => "%{TIMESTAMP_ISO8601:timestamp} %{WORD:service} %{WORD:component} %{LOGLEVEL:log_level} %{GREEDYDATA:log_message}"
      }
      tag_on_failure => ["_grokparsefailure", "application_parse_failure"]
      overwrite => ["message"]
    }
  }

  # Parse security logs
  if [type] == "security" {
    grok {
      match => {
        "message" => "%{TIMESTAMP_ISO8601:timestamp} %{WORD:security_event} %{WORD:security_component} %{WORD:security_level} %{GREEDYDATA:security_message}"
      }
      tag_on_failure => ["_grokparsefailure", "security_parse_failure"]
      add_field => { "log_type" => "security" }
    }
  }

  # Parse audit logs
  if [type] == "audit" {
    grok {
      match => {
        "message" => "%{TIMESTAMP_ISO8601:timestamp} %{WORD:audit_action} %{WORD:audit_component} %{WORD:user_id} %{GREEDYDATA:audit_message}"
      }
      tag_on_failure => ["_grokparsefailure", "audit_parse_failure"]
      add_field => { "log_type" => "audit" }
    }
  }

  # Standardize timestamp
  date {
    match => ["timestamp", "ISO8601"]
    target => "@timestamp"
    timezone => "UTC"
    remove_field => ["timestamp"]
  }

  # Parse JSON messages if present
  json {
    source => "message"
    target => "parsed_json"
    skip_on_invalid_json => true
    remove_field => ["message"]
  }

  # Enrich logs with additional context
  if "_grokparsefailure" not in [tags] {
    mutate {
      convert => {
        "response_time" => "float"
        "bytes" => "integer"
      }
      rename => {
        "host" => "source_host"
        "@version" => "logstash_version"
      }
    }
  }
}

# Output plugins configuration
output {
  elasticsearch {
    hosts => ["${ELASTICSEARCH_HOSTS}"]
    index => "enrollment-logs-%{+YYYY.MM.dd}"
    
    # SSL/TLS Configuration
    ssl => true
    ssl_certificate_verification => true
    ssl_certificate_authority => "/etc/logstash/certs/ca.crt"
    ssl_certificate => "/etc/logstash/certs/logstash.crt"
    ssl_key => "/etc/logstash/certs/logstash.key"
    ssl_verification_mode => "certificate"
    
    # Index Management
    template_name => "enrollment-logs"
    template_overwrite => true
    ilm_enabled => true
    ilm_policy => "enrollment-logs-policy"
    pipeline => "enrollment-logs-pipeline"
    
    # Retry Configuration
    retry_initial_interval => 2
    retry_max_interval => 64
    retry_on_conflict => 3
    
    # Buffer Configuration
    bulk_max_size => 5120
    flush_size => 500
    timeout => 60
  }

  # Dead Letter Queue for failed events
  if "_grokparsefailure" in [tags] {
    elasticsearch {
      hosts => ["${ELASTICSEARCH_HOSTS}"]
      index => "enrollment-logs-failed-%{+YYYY.MM.dd}"
      ssl => true
      ssl_certificate_authority => "/etc/logstash/certs/ca.crt"
      ssl_certificate => "/etc/logstash/certs/logstash.crt"
      ssl_key => "/etc/logstash/certs/logstash.key"
      ssl_verification_mode => "certificate"
    }
  }
}